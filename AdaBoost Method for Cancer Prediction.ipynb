{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you’ll explore the breast cancer dataset and try to train the model to predict if the person is having breast cancer or not. We will start off with a weak learner, a decision tree with maximum depth = 2.\n",
    "\n",
    "We will then build an adaboost ensemble with 50 trees with a step of 3 and compare the performance with the weak learner.\n",
    "\n",
    "Let's get started by loading the libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn import metrics\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the breast cancer dataset in which the target variable has 1 if the person has cancer and 0 otherwise. Let's load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer = load_breast_cancer()\n",
    "digits = load_digits()\n",
    "\n",
    "data = cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data= np.c_[data['data'], data['target']],\n",
    "                     columns= list(data['feature_names']) + ['target'])\n",
    "df['target'] = df['target'].astype('uint16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0          17.99         10.38          122.80     1001.0          0.11840   \n",
       "1          20.57         17.77          132.90     1326.0          0.08474   \n",
       "2          19.69         21.25          130.00     1203.0          0.10960   \n",
       "3          11.42         20.38           77.58      386.1          0.14250   \n",
       "4          20.29         14.34          135.10     1297.0          0.10030   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564        21.56         22.39          142.00     1479.0          0.11100   \n",
       "565        20.13         28.25          131.20     1261.0          0.09780   \n",
       "566        16.60         28.08          108.30      858.1          0.08455   \n",
       "567        20.60         29.33          140.10     1265.0          0.11780   \n",
       "568         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0             0.27760         0.30010              0.14710         0.2419   \n",
       "1             0.07864         0.08690              0.07017         0.1812   \n",
       "2             0.15990         0.19740              0.12790         0.2069   \n",
       "3             0.28390         0.24140              0.10520         0.2597   \n",
       "4             0.13280         0.19800              0.10430         0.1809   \n",
       "..                ...             ...                  ...            ...   \n",
       "564           0.11590         0.24390              0.13890         0.1726   \n",
       "565           0.10340         0.14400              0.09791         0.1752   \n",
       "566           0.10230         0.09251              0.05302         0.1590   \n",
       "567           0.27700         0.35140              0.15200         0.2397   \n",
       "568           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                   0.07871  ...          17.33           184.60      2019.0   \n",
       "1                   0.05667  ...          23.41           158.80      1956.0   \n",
       "2                   0.05999  ...          25.53           152.50      1709.0   \n",
       "3                   0.09744  ...          26.50            98.87       567.7   \n",
       "4                   0.05883  ...          16.67           152.20      1575.0   \n",
       "..                      ...  ...            ...              ...         ...   \n",
       "564                 0.05623  ...          26.40           166.10      2027.0   \n",
       "565                 0.05533  ...          38.25           155.00      1731.0   \n",
       "566                 0.05648  ...          34.12           126.70      1124.0   \n",
       "567                 0.07016  ...          39.42           184.60      1821.0   \n",
       "568                 0.05884  ...          30.37            59.16       268.6   \n",
       "\n",
       "     worst smoothness  worst compactness  worst concavity  \\\n",
       "0             0.16220            0.66560           0.7119   \n",
       "1             0.12380            0.18660           0.2416   \n",
       "2             0.14440            0.42450           0.4504   \n",
       "3             0.20980            0.86630           0.6869   \n",
       "4             0.13740            0.20500           0.4000   \n",
       "..                ...                ...              ...   \n",
       "564           0.14100            0.21130           0.4107   \n",
       "565           0.11660            0.19220           0.3215   \n",
       "566           0.11390            0.30940           0.3403   \n",
       "567           0.16500            0.86810           0.9387   \n",
       "568           0.08996            0.06444           0.0000   \n",
       "\n",
       "     worst concave points  worst symmetry  worst fractal dimension  target  \n",
       "0                  0.2654          0.4601                  0.11890       0  \n",
       "1                  0.1860          0.2750                  0.08902       0  \n",
       "2                  0.2430          0.3613                  0.08758       0  \n",
       "3                  0.2575          0.6638                  0.17300       0  \n",
       "4                  0.1625          0.2364                  0.07678       0  \n",
       "..                    ...             ...                      ...     ...  \n",
       "564                0.2216          0.2060                  0.07115       0  \n",
       "565                0.1628          0.2572                  0.06637       0  \n",
       "566                0.1418          0.2218                  0.07820       0  \n",
       "567                0.2650          0.4087                  0.12400       0  \n",
       "568                0.0000          0.2871                  0.07039       1  \n",
       "\n",
       "[569 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871  ...          17.33           184.60      2019.0   \n",
       "1                 0.05667  ...          23.41           158.80      1956.0   \n",
       "2                 0.05999  ...          25.53           152.50      1709.0   \n",
       "3                 0.09744  ...          26.50            98.87       567.7   \n",
       "4                 0.05883  ...          16.67           152.20      1575.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  target  \n",
       "0          0.4601                  0.11890       0  \n",
       "1          0.2750                  0.08902       0  \n",
       "2          0.3613                  0.08758       0  \n",
       "3          0.6638                  0.17300       0  \n",
       "4          0.2364                  0.07678       0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(455, 30)\n",
      "(455, 1)\n",
      "(114, 30)\n",
      "(114, 1)\n"
     ]
    }
   ],
   "source": [
    "# adaboost experiments\n",
    "# create x and y train\n",
    "X = df.drop('target', axis=1)\n",
    "y = df[['target']]\n",
    "\n",
    "# split data into train and test/validation sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=101)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target    0.626374\n",
      "dtype: float64\n",
      "target    0.631579\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# check the average cancer occurence rates in train and test data, should be comparable\n",
    "print(y_train.mean())\n",
    "print(y_test.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base estimator: a weak learner with max_depth=2\n",
    "shallow_tree = DecisionTreeClassifier(max_depth=2, random_state = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9385964912280702"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the shallow decision tree \n",
    "shallow_tree.fit(X_train, y_train)\n",
    "\n",
    "# test error\n",
    "y_pred = shallow_tree.predict(X_test)\n",
    "score = metrics.accuracy_score(y_test, y_pred)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will see the accuracy using the AdaBoost algorithm. In this following code, we will write code to calculate the accuracy of the AdaBoost models as we increase the number of trees from 1 to 50 with a step of 3 in the lines:\n",
    "\n",
    "'estimators = list(range(1, 50, 3))'\n",
    "\n",
    "'for n_est in estimators:'\n",
    "\n",
    "We finally end up with the accuracy of all the models in a single list abc_scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adaboost with the tree as base estimator\n",
    "\n",
    "estimators = list(range(1, 50, 3))\n",
    "\n",
    "abc_scores = []\n",
    "for n_est in estimators:\n",
    "    ABC = AdaBoostClassifier(\n",
    "    base_estimator=shallow_tree, \n",
    "    n_estimators = n_est)\n",
    "    \n",
    "    ABC.fit(X_train, y_train)\n",
    "    y_pred = ABC.predict(X_test)\n",
    "    score = metrics.accuracy_score(y_test, y_pred)\n",
    "    abc_scores.append(score)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9473684210526315,\n",
       " 0.956140350877193,\n",
       " 0.9912280701754386,\n",
       " 0.9385964912280702,\n",
       " 0.9649122807017544,\n",
       " 0.956140350877193,\n",
       " 0.9649122807017544,\n",
       " 0.956140350877193,\n",
       " 0.956140350877193,\n",
       " 0.9649122807017544,\n",
       " 0.9649122807017544,\n",
       " 0.9912280701754386,\n",
       " 0.9736842105263158,\n",
       " 0.9736842105263158,\n",
       " 0.9736842105263158,\n",
       " 0.9824561403508771,\n",
       " 0.9912280701754386]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abc_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot test scores and n_estimators\n",
    "# plot\n",
    "plt.plot(estimators, abc_scores)\n",
    "plt.xlabel('n_estimators')\n",
    "plt.ylabel('accuracy')\n",
    "plt.ylim([0.85, 1])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
